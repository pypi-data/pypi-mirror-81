
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>joblib.Parallel &#8212; joblib 0.16.0 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="joblib.dump" href="joblib.dump.html" />
    <link rel="prev" title="joblib.Memory" href="joblib.Memory.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="joblib-parallel">
<h1><a class="reference internal" href="../index.html#module-joblib" title="joblib"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code></a>.Parallel<a class="headerlink" href="#joblib-parallel" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="joblib.Parallel">
<em class="property">class </em><code class="sig-prename descclassname">joblib.</code><code class="sig-name descname">Parallel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">backend</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pre_dispatch</span><span class="o">=</span><span class="default_value">'2 * n_jobs'</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">temp_folder</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_nbytes</span><span class="o">=</span><span class="default_value">'1M'</span></em>, <em class="sig-param"><span class="n">mmap_mode</span><span class="o">=</span><span class="default_value">'r'</span></em>, <em class="sig-param"><span class="n">prefer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">require</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.Parallel" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper class for readable parallel mapping.</p>
<p>Read more in the <a class="reference internal" href="../parallel.html#parallel"><span class="std std-ref">User Guide</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>n_jobs: int, default: None</strong></dt><dd><p>The maximum number of concurrently running jobs, such as the number
of Python worker processes when backend=”multiprocessing”
or the size of the thread-pool when backend=”threading”.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. For n_jobs below -1,
(n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all
CPUs but one are used.
None is a marker for ‘unset’ that will be interpreted as n_jobs=1
(sequential execution) unless the call is performed under a
parallel_backend context manager that sets another value for
n_jobs.</p>
</dd>
<dt><strong>backend: str, ParallelBackendBase instance or None, default: ‘loky’</strong></dt><dd><p>Specify the parallelization backend implementation.
Supported backends are:</p>
<ul class="simple">
<li><p>“loky” used by default, can induce some
communication and memory overhead when exchanging input and
output data with the worker Python processes.</p></li>
<li><p>“multiprocessing” previous process-based backend based on
<cite>multiprocessing.Pool</cite>. Less robust than <cite>loky</cite>.</p></li>
<li><p>“threading” is a very low-overhead backend but it suffers
from the Python Global Interpreter Lock if the called function
relies a lot on Python objects. “threading” is mostly useful
when the execution bottleneck is a compiled extension that
explicitly releases the GIL (for instance a Cython loop wrapped
in a “with nogil” block or an expensive call to a library such
as NumPy).</p></li>
<li><p>finally, you can register backends by calling
register_parallel_backend. This will allow you to implement
a backend of your liking.</p></li>
</ul>
<p>It is not recommended to hard-code the backend name in a call to
Parallel in a library. Instead it is recommended to set soft hints
(prefer) or hard constraints (require) so as to make it possible
for library users to change the backend from the outside using the
parallel_backend context manager.</p>
</dd>
<dt><strong>prefer: str in {‘processes’, ‘threads’} or None, default: None</strong></dt><dd><p>Soft hint to choose the default backend if no specific backend
was selected with the parallel_backend context manager. The
default process-based backend is ‘loky’ and the default
thread-based backend is ‘threading’. Ignored if the <code class="docutils literal notranslate"><span class="pre">backend</span></code>
parameter is specified.</p>
</dd>
<dt><strong>require: ‘sharedmem’ or None, default None</strong></dt><dd><p>Hard constraint to select the backend. If set to ‘sharedmem’,
the selected backend will be single-host and thread-based even
if the user asked for a non-thread based backend with
parallel_backend.</p>
</dd>
<dt><strong>verbose: int, optional</strong></dt><dd><p>The verbosity level: if non zero, progress messages are
printed. Above 50, the output is sent to stdout.
The frequency of the messages increases with the verbosity level.
If it more than 10, all iterations are reported.</p>
</dd>
<dt><strong>timeout: float, optional</strong></dt><dd><p>Timeout limit for each task to complete.  If any task takes longer
a TimeOutError will be raised. Only applied when n_jobs != 1</p>
</dd>
<dt><strong>pre_dispatch: {‘all’, integer, or expression, as in ‘3*n_jobs’}</strong></dt><dd><p>The number of batches (of tasks) to be pre-dispatched.
Default is ‘2*n_jobs’. When batch_size=”auto” this is reasonable
default and the workers should never starve.</p>
</dd>
<dt><strong>batch_size: int or ‘auto’, default: ‘auto’</strong></dt><dd><p>The number of atomic tasks to dispatch at once to each
worker. When individual evaluations are very fast, dispatching
calls to workers can be slower than sequential computation because
of the overhead. Batching fast computations together can mitigate
this.
The <code class="docutils literal notranslate"><span class="pre">'auto'</span></code> strategy keeps track of the time it takes for a batch
to complete, and dynamically adjusts the batch size to keep the time
on the order of half a second, using a heuristic. The initial batch
size is 1.
<code class="docutils literal notranslate"><span class="pre">batch_size=&quot;auto&quot;</span></code> with <code class="docutils literal notranslate"><span class="pre">backend=&quot;threading&quot;</span></code> will dispatch
batches of a single task at a time as the threading backend has
very little overhead and using larger batch size has not proved to
bring any gain in that case.</p>
</dd>
<dt><strong>temp_folder: str, optional</strong></dt><dd><p>Folder to be used by the pool for memmapping large arrays
for sharing memory with worker processes. If None, this will try in
order:</p>
<ul class="simple">
<li><p>a folder pointed by the JOBLIB_TEMP_FOLDER environment
variable,</p></li>
<li><p>/dev/shm if the folder exists and is writable: this is a
RAM disk filesystem available by default on modern Linux
distributions,</p></li>
<li><p>the default system temporary folder that can be
overridden with TMP, TMPDIR or TEMP environment
variables, typically /tmp under Unix operating systems.</p></li>
</ul>
<p>Only active when backend=”loky” or “multiprocessing”.</p>
</dd>
<dt><strong>max_nbytes int, str, or None, optional, 1M by default</strong></dt><dd><p>Threshold on the size of arrays passed to the workers that
triggers automated memory mapping in temp_folder. Can be an int
in Bytes, or a human-readable string, e.g., ‘1M’ for 1 megabyte.
Use None to disable memmapping of large arrays.
Only active when backend=”loky” or “multiprocessing”.</p>
</dd>
<dt><strong>mmap_mode: {None, ‘r+’, ‘r’, ‘w+’, ‘c’}</strong></dt><dd><p>Memmapping mode for numpy arrays passed to workers.
See ‘max_nbytes’ parameter documentation for more details.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This object uses workers to compute in parallel the application of a
function to many different arguments. The main functionality it brings
in addition to using the raw multiprocessing or concurrent.futures API
are (see examples for details):</p>
<ul class="simple">
<li><p>More readable code, in particular since it avoids
constructing list of arguments.</p></li>
<li><dl class="simple">
<dt>Easier debugging:</dt><dd><ul>
<li><p>informative tracebacks even when the error happens on
the client side</p></li>
<li><p>using ‘n_jobs=1’ enables to turn off parallel computing
for debugging without changing the codepath</p></li>
<li><p>early capture of pickling errors</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>An optional progress meter.</p></li>
<li><p>Interruption of multiprocesses jobs with ‘Ctrl-C’</p></li>
<li><p>Flexible pickling control for the communication to and from
the worker processes.</p></li>
<li><p>Ability to use shared memory efficiently with worker
processes for large numpy-based datastructures.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>A simple example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="go">[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]</span>
</pre></div>
</div>
<p>Reshaping the output when the function has several return
values:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">modf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">modf</span><span class="p">)(</span><span class="n">i</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">r</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">(0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">i</span>
<span class="go">(0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)</span>
</pre></div>
</div>
<p>The progress meter: the higher the value of <cite>verbose</cite>, the more
messages:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">sleep</span><span class="p">)(</span><span class="o">.</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> 
<span class="go">[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.6s</span>
<span class="go">[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.8s</span>
<span class="go">[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    1.4s finished</span>
</pre></div>
</div>
<p>Traceback example, note how the line of the error is indicated
as well as the values of the parameter passed to the function that
triggered the exception, even though the traceback happens in the
child process:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">nlargest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">delayed</span><span class="p">(</span><span class="n">nlargest</span><span class="p">)(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="s1">&#39;abcde&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> 
<span class="go">#...</span>
<span class="go">---------------------------------------------------------------------------</span>
<span class="go">Sub-process traceback:</span>
<span class="go">---------------------------------------------------------------------------</span>
<span class="go">TypeError                                          Mon Nov 12 11:37:46 2012</span>
<span class="go">PID: 12934                                    Python 2.7.3: /usr/bin/python</span>
<span class="go">...........................................................................</span>
<span class="go">/usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)</span>
<span class="go">    419         if n &gt;= size:</span>
<span class="go">    420             return sorted(iterable, key=key, reverse=True)[:n]</span>
<span class="go">    421</span>
<span class="go">    422     # When key is none, use simpler decoration</span>
<span class="go">    423     if key is None:</span>
<span class="go">--&gt; 424         it = izip(iterable, count(0,-1))                    # decorate</span>
<span class="go">    425         result = _nlargest(n, it)</span>
<span class="go">    426         return map(itemgetter(0), result)                   # undecorate</span>
<span class="go">    427</span>
<span class="go">    428     # General case, slowest method</span>
<span class="go"> TypeError: izip argument #1 must support iteration</span>
<span class="go">___________________________________________________________________________</span>
</pre></div>
</div>
<p>Using pre_dispatch in a producer/consumer situation, where the
data is generated on the fly. Note how the producer is first
called 3 times before the parallel loop is initiated, and then
called to generate new data on the fly:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">producer</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Produced </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">yield</span> <span class="n">i</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">pre_dispatch</span><span class="o">=</span><span class="s1">&#39;1.5*n_jobs&#39;</span><span class="p">)(</span>
<span class="gp">... </span>               <span class="n">delayed</span><span class="p">(</span><span class="n">sqrt</span><span class="p">)(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">producer</span><span class="p">())</span> 
<span class="go">Produced 0</span>
<span class="go">Produced 1</span>
<span class="go">Produced 2</span>
<span class="go">[Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 3</span>
<span class="go">[Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 4</span>
<span class="go">[Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s</span>
<span class="go">Produced 5</span>
<span class="go">[Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s</span>
<span class="go">[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s remaining: 0.0s</span>
<span class="go">[Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished</span>
</pre></div>
</div>
<dl class="py method">
<dt id="joblib.Parallel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">backend</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">timeout</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pre_dispatch</span><span class="o">=</span><span class="default_value">'2 * n_jobs'</span></em>, <em class="sig-param"><span class="n">batch_size</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">temp_folder</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_nbytes</span><span class="o">=</span><span class="default_value">'1M'</span></em>, <em class="sig-param"><span class="n">mmap_mode</span><span class="o">=</span><span class="default_value">'r'</span></em>, <em class="sig-param"><span class="n">prefer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">require</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#joblib.Parallel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>depth: int, optional</strong></dt><dd><p>The depth of objects printed.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#joblib.Parallel.__init__" title="joblib.Parallel.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>([n_jobs, backend, verbose, …])</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">debug</span></code>(msg)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dispatch_next</span></code>()</p></td>
<td><p>Dispatch more data for parallel processing</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dispatch_one_batch</span></code>(iterator)</p></td>
<td><p>Prefetch the tasks for the next batch and dispatch them.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">format</span></code>(obj[, indent])</p></td>
<td><p>Return the formatted representation of the object.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">print_progress</span></code>()</p></td>
<td><p>Display the process of the parallel execution only a fraction of time, controlled by self.verbose.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieve</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">warn</span></code>(msg)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="examples-using-joblib-parallel">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">joblib.Parallel</span></code><a class="headerlink" href="#examples-using-joblib-parallel" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Randomness is affected by parallel execution differently by the different backends."><div class="figure align-default" id="id1">
<img alt="Random state within joblib.Parallel" src="../_images/sphx_glr_parallel_random_state_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/parallel_random_state.html#sphx-glr-auto-examples-parallel-random-state-py"><span class="std std-ref">Random state within joblib.Parallel</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to cache intermediate computing results using joblib.Memory within..."><div class="figure align-default" id="id2">
<img alt="Checkpoint using joblib.Memory and joblib.Parallel" src="../_images/sphx_glr_nested_parallel_memory_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/nested_parallel_memory.html#sphx-glr-auto-examples-nested-parallel-memory-py"><span class="std std-ref">Checkpoint using joblib.Memory and joblib.Parallel</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example highlights the options for tempering with joblib serialization process."><div class="figure align-default" id="id3">
<img alt="Serialization of un-picklable objects" src="../_images/sphx_glr_serialization_and_wrappers_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/serialization_and_wrappers.html#sphx-glr-auto-examples-serialization-and-wrappers-py"><span class="std std-ref">Serialization of un-picklable objects</span></a></span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example illustrates some features enabled by using a memory map (:class:`numpy.memmap`) wi..."><div class="figure align-default" id="id4">
<img alt="NumPy memmap in joblib.Parallel" src="../_images/sphx_glr_parallel_memmap_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/parallel_memmap.html#sphx-glr-auto-examples-parallel-memmap-py"><span class="std std-ref">NumPy memmap in joblib.Parallel</span></a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
</div><div class="sphx-glr-thumbcontainer" tooltip="This example shows the simplest usage of the dask `distributed &lt;https://distributed.readthedocs..."><div class="figure align-default" id="id5">
<img alt="Using dask distributed for single-machine parallel computing" src="../_images/sphx_glr_distributed_backend_simple_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../auto_examples/parallel/distributed_backend_simple.html#sphx-glr-auto-examples-parallel-distributed-backend-simple-py"><span class="std std-ref">Using dask distributed for single-machine parallel computing</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div><div class="clearer"></div></div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/joblib_logo.svg" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../why.html">Why joblib: project goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Installing joblib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory.html">On demand recomputing: the <cite>Memory</cite> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallel.html">Embarrassingly parallel for loops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../persistence.html">Persistence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developing.html">Development</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="joblib.Memory.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.Memory</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.Parallel</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#examples-using-joblib-parallel">Examples using <code class="docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="joblib.dump.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="joblib.load.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.load</a></li>
<li class="toctree-l1"><a class="reference internal" href="joblib.hash.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.hash</a></li>
<li class="toctree-l1"><a class="reference internal" href="joblib.register_compressor.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">joblib</span></code>.register_compressor</a></li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2008-2018, Joblib developers.
      
      |
      <a href="../_sources/generated/joblib.Parallel.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>